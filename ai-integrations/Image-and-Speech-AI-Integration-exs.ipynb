{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install Required Libraries\n",
        "This cell installs the three main SDKs we’ll need:\n",
        "\n",
        "OpenAI → for story text generation.\n",
        "\n",
        "Google Generative AI (Gemini 2.5 Flash) → for generating and editing fairy-tale images.\n",
        "\n",
        "ElevenLabs → for converting generated text into speech.\n",
        "\n",
        "We also print out their versions to confirm successful installation."
      ],
      "metadata": {
        "id": "XThjsrv2R2n9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oos0KjhuM103",
        "outputId": "a109f110-b79a-41f7-b455-1374eb37fc13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/928.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m928.2/928.2 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/858.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m858.7/858.7 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hOpenAI version: 1.105.0\n",
            "Google Generative AI version: 0.8.5\n",
            "ElevenLabs version: 2.13.0\n"
          ]
        }
      ],
      "source": [
        "# 📦 Install core AI libraries\n",
        "!pip install -q --upgrade openai google-generativeai elevenlabs\n",
        "\n",
        "# ✅ Check installed versions\n",
        "import openai, google.generativeai as genai, elevenlabs\n",
        "print(\"OpenAI version:\", openai.__version__)\n",
        "print(\"Google Generative AI version:\", genai.__version__)\n",
        "print(\"ElevenLabs version:\", elevenlabs.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Enter Input Topic\n",
        "\n",
        "This cell allows you to define the topic of the fairy tale.\n",
        "The topic will later be passed to OpenAI to generate a story, to Gemini for image creation, and to ElevenLabs for narration."
      ],
      "metadata": {
        "id": "GcovmiSzSNfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🎭 Input Cell: Define the fairy tale topic\n",
        "# You can change the text below to any theme or idea you want.\n",
        "# Example: \"A little dragon who wants to learn how to sing.\"\n",
        "\n",
        "topic = input(\"✨ Enter the topic for your fairy tale: \")\n",
        "\n",
        "print(f\"✅ Topic set: {topic}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVR6ze5USNRr",
        "outputId": "79578040-dbd8-473a-dfc6-2aa9c9e67152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨ Enter the topic for your fairy tale: A boy who wants to develop a robot to build a spacecraft in order to be able to travel beyond the solar system\n",
            "✅ Topic set: A boy who wants to develop a robot to build a spacecraft in order to be able to travel beyond the solar system\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Enhance the Topic with OpenAI (GPT-4o-mini)\n",
        "\n",
        "This cell uses OpenAI’s GPT-4o-mini to expand and enrich the topic.\n",
        "The goal is to transform a short idea into a detailed fairy tale concept (characters, setting, mood, possible conflicts) — without yet writing the story itself."
      ],
      "metadata": {
        "id": "BykqW9J2TMu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🧠 Enhance Topic with OpenAI GPT-4o-mini\n",
        "# Expands the topic into a richer concept (characters, setting, mood)\n",
        "# but does NOT create the full story yet.\n",
        "\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata # Import userdata\n",
        "\n",
        "# Initialize OpenAI client (make sure OPENAI_API_KEY is set in Colab's secrets)\n",
        "# Use userdata.get to access the secret\n",
        "client = OpenAI(api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are an assistant helping to create a fairy tale.\n",
        "Take this topic: \"{topic}\" and expand it into a detailed fairy tale concept.\n",
        "Include:\n",
        "- Main characters and their traits also physical traits for each character as well.\n",
        "- Setting (world, time, magical elements)\n",
        "- Central theme or conflict\n",
        "- Tone/mood of the story\n",
        "\n",
        "Do NOT write the story yet. Just develop the concept.\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant for creating fairy tales.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    max_tokens=900,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "enhanced_topic = response.choices[0].message.content\n",
        "print(\"✨ Enhanced Fairy Tale Concept:\\n\")\n",
        "print(enhanced_topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrlX99AVSNOT",
        "outputId": "2edd9189-18f8-4167-954a-d11bf4551860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨ Enhanced Fairy Tale Concept:\n",
            "\n",
            "**Fairy Tale Concept: \"Starlight Dreams\"**\n",
            "\n",
            "**Main Characters:**\n",
            "\n",
            "1. **Eliot**:\n",
            "   - **Traits**: Curious, adventurous, resourceful, imaginative, enthusiastic.\n",
            "   - **Physical Description**: Eliot has tousled chestnut hair that constantly seems windswept from his expeditions. He has bright blue eyes that sparkle with wonder, a sprinkle of freckles across his nose, and a lean frame from climbing trees and exploring. He often wears a patchwork vest filled with various gadgets and a pair of goggles perched on his forehead, ready for his next adventure.\n",
            "\n",
            "2. **Rusty**:\n",
            "   - **Traits**: Loyal, quirky, innocent, humorous, evolving.\n",
            "   - **Physical Description**: Rusty is a small, humanoid robot built from a mix of scrap metal, gears, and old electronic parts. His body is slightly uneven, giving him an endearing wobble when he walks. His eyes are glowing orbs that change color based on his mood, and he has a playful smile etched onto his metallic face. Rusty often sports a mismatched collection of buttons and gadgets attached to his body, showcasing his evolving nature.\n",
            "\n",
            "3. **Luna**:\n",
            "   - **Traits**: Wise, mystical, nurturing, insightful, enigmatic.\n",
            "   - **Physical Description**: Luna is a majestic owl with feathers that shimmer like stardust, varying in shades of deep blue and silver. Her large, luminous eyes are filled with wisdom and glint with knowledge of the cosmos. She has an air of grace and poise, often perched on a low branch with her wings elegantly folded. Her presence radiates a calming aura, and she often wears a delicate necklace of tiny stars that twinkle faintly.\n",
            "\n",
            "4. **The Cloudsmith**:\n",
            "   - **Traits**: Mysterious, reclusive, skilled, contemplative, transformative.\n",
            "   - **Physical Description**: The Cloudsmith is a tall figure cloaked in billowing robes that seem to blend with the clouds around him. His hair is wild and white, resembling wisps of cloud, and his face is lined with age and wisdom. He carries a staff topped with a swirling cloud that glows softly, and his hands are often stained with colors from his cloud-shaping creations. His eyes are a deep, stormy gray, reflecting the skies he masters.\n",
            "\n",
            "**Setting:**\n",
            "\n",
            "- **World**: The story unfolds in Starhaven, a whimsical village that brims with creativity and wonder. The village is dotted with colorful cottages, each adorned with twinkling lights and vibrant gardens filled with magical plants that hum and glow. Surrounding the village is the Enchanted Forest, home to fantastical creatures like talking animals and fairies, and filled with trees that whisper ancient secrets. High above, the sky is a swirling tapestry of colors, with stars that seem to dance and change shape.\n",
            "\n",
            "- **Time**: The time is a blend of the past and future, where steam-powered machines coexist with magical elements. The village celebrates both tradition and innovation, embracing the old ways of magic while welcoming new inventions that enhance their lives.\n",
            "\n",
            "- **Magical Elements**: Magic is woven into the fabric of daily life in Starhaven. The villagers use potions for healing, enchanted tools for crafting, and magical creatures as companions. The stars play a significant role, believed to hold dreams and wishes, with the ability to communicate with those who are attuned to their whispers.\n",
            "\n",
            "**Central Theme or Conflict:**\n",
            "\n",
            "The central theme of \"Starlight Dreams\" revolves around the pursuit of dreams and the importance of believing in oneself. Eliot's journey involves not only chasing his dream of exploring the universe but also learning to balance ambition with reality. The conflict arises from Eliot's struggle against self-doubt, external skepticism, and the challenges posed by the Cloudsmith, who initially doubts Eliot's abilities. Throughout the story, Eliot, with the help of Rusty, Luna, and the Cloudsmith, learns to embrace his imagination, overcome obstacles, and understand that dreams require both belief and hard work.\n",
            "\n",
            "**Tone/Mood of the Story:**\n",
            "\n",
            "The tone of \"Starlight Dreams\" is whimsical and adventurous, filled with a sense of wonder and discovery. It captures the magic of childhood dreams while exploring deeper themes of growth and self-belief. The mood shifts between lighthearted moments filled with humor and deeper, reflective scenes that encourage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Extract Characters with Structured Outputs & Save JSON File\n",
        "\n",
        "This cell takes the enhanced fairy tale concept and uses OpenAI GPT-4o-mini with structured outputs to reliably extract the main characters.\n",
        "For each character, it generates:\n",
        "\n",
        "char_name → the character’s name\n",
        "\n",
        "prompt → a ready-to-use image generation prompt starting with “Generate me image of…”\n",
        "\n",
        "The result is guaranteed to be valid JSON (thanks to a schema) and is saved as a file (characters.json).\n",
        "This makes it easy to reuse the characters later when generating their illustrations with Gemini.\n",
        "\n",
        "What it does step-by-step:\n",
        "\n",
        "\n",
        "1.   Defines a strict JSON Schema with the required fields (char_name, prompt).\n",
        "2.   Sends the enhanced concept to GPT-4o-mini and enforces the schema.\n",
        "3.   Prints the structured results in Colab.\n",
        "4.   Saves the characters and prompts into a file characters.json.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UrFAnh1TZy8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🧩 Structured JSON Extraction of Character Prompts (Strict Schema, root object)\n",
        "\n",
        "import json\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# Reuse existing client if defined; otherwise init here\n",
        "client = globals().get(\"client\") or OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"additionalProperties\": False,\n",
        "    \"properties\": {\n",
        "        \"characters\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\n",
        "                \"type\": \"object\",\n",
        "                \"additionalProperties\": False,\n",
        "                \"properties\": {\n",
        "                    \"char_name\": {\"type\": \"string\", \"minLength\": 1},\n",
        "                    \"prompt\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"minLength\": 10,\n",
        "                        \"pattern\": r\"^Generate me image of\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"char_name\", \"prompt\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"required\": [\"characters\"]\n",
        "}\n",
        "\n",
        "instruction = f\"\"\"\n",
        "From the following fairy tale concept, extract the DISTINCT main characters.\n",
        "For EACH character, produce:\n",
        "- char_name: the character’s name\n",
        "- prompt: start EXACTLY with \"Generate me image of\" and then give a concise, vivid,\n",
        "  single-image description combining physical traits, attire, notable props, age,\n",
        "  mood, and setting hints. Avoid backstory and plot; no camera jargon; 1–2 sentences.\n",
        "\n",
        "Constraints:\n",
        "- Output ONLY a JSON object with a single key \"characters\" whose value is the array.\n",
        "- No other keys or text.\n",
        "- No duplicate characters. No empty or generic entries.\n",
        "- Keep each prompt specific enough to illustrate a single portrait/full-body image.\n",
        "- Do NOT invent new characters unless the concept clearly implies them.\n",
        "\n",
        "Fairy Tale Concept:\n",
        "{enhanced_topic}\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You return only JSON that strictly matches the provided schema.\"},\n",
        "        {\"role\": \"user\", \"content\": instruction}\n",
        "    ],\n",
        "    response_format={\n",
        "        \"type\": \"json_schema\",\n",
        "        \"json_schema\": {\n",
        "            \"name\": \"character_image_prompts\",\n",
        "            \"strict\": True,\n",
        "            \"schema\": schema\n",
        "        }\n",
        "    },\n",
        "    temperature=0.4,\n",
        "    max_tokens=900,\n",
        ")\n",
        "\n",
        "\n",
        "raw_json = response.choices[0].message.content\n",
        "data = json.loads(raw_json)\n",
        "\n",
        "# Extract array for convenience\n",
        "characters_data = data[\"characters\"]\n",
        "\n",
        "# Pretty print\n",
        "print(\"✅ Extracted Character Prompts (JSON):\\n\")\n",
        "print(json.dumps(characters_data, indent=2))\n",
        "\n",
        "# Save to file\n",
        "json_file = \"characters.json\"\n",
        "with open(json_file, \"w\") as f:\n",
        "    json.dump(characters_data, f, indent=2)\n",
        "\n",
        "print(f\"\\n💾 Saved character prompts to {json_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YhrfYr1YgAw",
        "outputId": "653a821f-5fe3-441d-aeb4-078bf93710cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extracted Character Prompts (JSON):\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"char_name\": \"Eliot\",\n",
            "    \"prompt\": \"Generate me image of a curious young boy with tousled chestnut hair and bright blue eyes, wearing a patchwork vest filled with gadgets and goggles on his forehead, standing in a whimsical village surrounded by colorful cottages and glowing gardens, exuding enthusiasm and adventure.\"\n",
            "  },\n",
            "  {\n",
            "    \"char_name\": \"Rusty\",\n",
            "    \"prompt\": \"Generate me image of a small, humanoid robot made of scrap metal and gears, with glowing orb eyes that change color, a playful smile on his metallic face, and a mismatched collection of buttons and gadgets attached to his body, wobbling in a vibrant garden filled with magical plants.\"\n",
            "  },\n",
            "  {\n",
            "    \"char_name\": \"Luna\",\n",
            "    \"prompt\": \"Generate me image of a majestic owl with shimmering feathers in shades of deep blue and silver, large luminous eyes filled with wisdom, perched gracefully on a branch, wearing a delicate necklace of tiny twinkling stars against a backdrop of a swirling, colorful sky.\"\n",
            "  },\n",
            "  {\n",
            "    \"char_name\": \"The Cloudsmith\",\n",
            "    \"prompt\": \"Generate me image of a tall figure cloaked in billowing robes blending with clouds, with wild white hair and stormy gray eyes, holding a staff topped with a glowing swirling cloud, standing contemplatively in a dreamy landscape filled with soft, fluffy clouds.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "💾 Saved character prompts to characters.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Generate the Fairy Tale & Save to TXT\n",
        "\n",
        "Creates a complete fairy tale based solely on enhanced_topic, using GPT-4o-mini.\n",
        "Saves the result as a .txt file so you can reuse it for narration and video later."
      ],
      "metadata": {
        "id": "njOy4jCvfENg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📖 Generate Full Fairy Tale from the Enhanced Concept and Save to TXT\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from datetime import datetime\n",
        "\n",
        "# Reuse existing OpenAI client or initialize a new one\n",
        "client = globals().get(\"client\") or OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Safety checks\n",
        "if \"enhanced_topic\" not in globals() or not enhanced_topic.strip():\n",
        "    raise ValueError(\"enhanced_topic is empty or missing. Please run the topic enhancement cell first.\")\n",
        "\n",
        "system_msg = (\n",
        "    \"You are a master fairy-tale writer. Write a vivid, emotionally engaging fairy tale \"\n",
        "    \"appropriate for a wide audience (children-friendly but enjoyable for adults). \"\n",
        "    \"Use clear structure (beginning, middle, resolution), rich sensory details, \"\n",
        "    \"and natural dialogue. Avoid violence and horror. Keep it timeless.\"\n",
        ")\n",
        "\n",
        "user_prompt = f\"\"\"\n",
        "Write a complete fairy tale based ONLY on this concept (do not reprint the concept):\n",
        "\n",
        "--- ENHANCED CONCEPT START ---\n",
        "{enhanced_topic}\n",
        "--- ENHANCED CONCEPT END ---\n",
        "\n",
        "Requirements:\n",
        "- 500–700 words.\n",
        "- Clear 3-act structure (setup, challenge, resolution).\n",
        "- Gentle moral/theme emerging naturally from events.\n",
        "- Suitable for high-quality TTS narration (short to medium sentences, varied rhythm).\n",
        "- No meta commentary. Do NOT include outlines or bullet points — prose only.\n",
        "\n",
        "Should be as a plain text, no special characters or formatting.\n",
        "\"\"\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_msg},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ],\n",
        "    temperature=0.8,\n",
        "    max_tokens=2000\n",
        ")\n",
        "\n",
        "story = resp.choices[0].message.content.strip()\n",
        "\n",
        "# Save to file with timestamped name for versioning\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "story_filename = f\"fairy_tale_story_{timestamp}.txt\"\n",
        "with open(story_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(story)\n",
        "\n",
        "print(f\"✅ Story generated and saved to: {story_filename}\\n\")\n",
        "print(\"📝 Preview (first 600 chars):\\n\")\n",
        "print(story[:600] + (\"...\" if len(story) > 600 else \"\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwqi5ANbd7Nv",
        "outputId": "a1c7fd8c-0b8c-4235-99cd-25bc3fc63475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Story generated and saved to: fairy_tale_story_20250903_164706.txt\n",
            "\n",
            "📝 Preview (first 600 chars):\n",
            "\n",
            "In the enchanting village of Starhaven, where the air hummed with magic and creativity, lived a curious boy named Eliot. With tousled chestnut hair and bright blue eyes that sparkled like the stars above, Eliot spent his days exploring the vibrant gardens and climbing the tallest trees. His patchwork vest, filled with gadgets he had created, was a testament to his imaginative spirit. Always ready for adventure, he often wore a pair of goggles on his forehead, dreaming of the day he could explore the universe beyond.\n",
            "\n",
            "One sunny morning, with the scent of blooming flowers wafting through the air...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "-9YFgazFSMWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🖼️ Robust character image generation with retries (Gemini 2.5 Flash preview)\n",
        "\n",
        "import os, json, re, base64, time\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import google.generativeai as genai\n",
        "\n",
        "# 1) Configure Gemini\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\") or os.getenv(\"GOOGLE_API_KEY\")\n",
        "except Exception:\n",
        "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "assert GOOGLE_API_KEY, \"Set GOOGLE_API_KEY\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel(\"gemini-2.5-flash-image-preview\")\n",
        "\n",
        "# 2) Load characters\n",
        "with open(\"characters.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    characters = json.load(f)\n",
        "\n",
        "# 3) Output folder\n",
        "os.makedirs(\"characters_images\", exist_ok=True)\n",
        "\n",
        "# 4) Helper for filenames\n",
        "def fname(s: str) -> str:\n",
        "    import re\n",
        "    s = re.sub(r\"\\s+\", \"_\", s.strip().lower())\n",
        "    return re.sub(r\"[^a-z0-9_\\-]\", \"\", s) or \"character\"\n",
        "\n",
        "# 5) Small helper to call the API with retries\n",
        "def generate_image_bytes(prompt: str, max_retries: int = 3, base_delay: float = 1.0):\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            res = model.generate_content(\n",
        "                prompt,\n",
        "                generation_config=genai.types.GenerationConfig(\n",
        "                    temperature=0.6,\n",
        "                    candidate_count=1,\n",
        "                ),\n",
        "            )\n",
        "            parts = getattr(res, \"parts\", None) or res.candidates[0].content.parts\n",
        "            for p in parts:\n",
        "                inline = getattr(p, \"inline_data\", None)\n",
        "                if inline and getattr(inline, \"mime_type\", \"\").startswith(\"image/\"):\n",
        "                    return inline.data if isinstance(inline.data, (bytes, bytearray)) else base64.b64decode(inline.data)\n",
        "            # If no image part, raise to trigger retry\n",
        "            raise RuntimeError(\"No image returned in response.\")\n",
        "        except Exception as e:\n",
        "            if attempt == max_retries:\n",
        "                raise\n",
        "            sleep_for = base_delay * (2 ** (attempt - 1))\n",
        "            print(f\"   -> Attempt {attempt} failed: {e}. Retrying in {sleep_for:.1f}s...\")\n",
        "            time.sleep(sleep_for)\n",
        "\n",
        "# 6) Iterate characters and generate images\n",
        "manifest = []\n",
        "for i, ch in enumerate(characters, 1):\n",
        "    name = ch.get(\"char_name\", f\"Character_{i}\")\n",
        "    prompt = ch.get(\"prompt\", \"\")\n",
        "    if not prompt:\n",
        "        print(f\"[{i}/{len(characters)}] {name} -> skipped (empty prompt)\")\n",
        "        continue\n",
        "\n",
        "    print(f\"[{i}/{len(characters)}] {name}\")\n",
        "    try:\n",
        "        img_bytes = generate_image_bytes(prompt)\n",
        "        img = Image.open(BytesIO(img_bytes))\n",
        "        path = os.path.join(\"characters_images\", f\"{i:02d}_{fname(name)}.png\")\n",
        "        img.save(path)\n",
        "        print(f\"  -> Saved {path}\")\n",
        "        manifest.append({\"char_name\": name, \"prompt\": prompt, \"image_path\": path})\n",
        "    except Exception as e:\n",
        "        print(f\"  -> Failed for {name}: {e}\")\n",
        "\n",
        "# 7) Save manifest\n",
        "with open(os.path.join(\"characters_images\", \"manifest.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(manifest, f, ensure_ascii=False, indent=2)\n",
        "print(\"📒 Manifest saved to characters_images/manifest.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "nW5Iu-YMjIpG",
        "outputId": "6a4b34db-d1c7-4b21-9bae-15daeeb292e3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/4] Eliot\n",
            "  -> Saved characters_images/01_eliot.png\n",
            "[2/4] Rusty\n",
            "  -> Saved characters_images/02_rusty.png\n",
            "[3/4] Luna\n",
            "  -> Saved characters_images/03_luna.png\n",
            "[4/4] The Cloudsmith\n",
            "  -> Saved characters_images/04_the_cloudsmith.png\n",
            "📒 Manifest saved to characters_images/manifest.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Extract 10 Key Scenes (Structured JSON) & Save\n",
        "\n",
        "This cell reads the full story, uses GPT-4o-mini with a strict JSON schema to produce exactly 10 scenes in order, and saves them to scenes.json. Each scene includes:\n",
        "\n",
        "characters_involved — list of character names (strings)\n",
        "\n",
        "scene_prompt — concise image prompt starting with “Generate me image of …”"
      ],
      "metadata": {
        "id": "hN5uzuYBn8io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🎬 Extract 10 Key Scenes from Story (Strict JSON) and Save\n",
        "\n",
        "import os, json\n",
        "from openai import OpenAI\n",
        "\n",
        "# Reuse existing client or init\n",
        "client = globals().get(\"client\") or OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Load the latest story file if variable 'story' is present; else raise\n",
        "if \"story\" not in globals() or not story.strip():\n",
        "    raise ValueError(\"Missing 'story'. Please run the story generation cell first.\")\n",
        "\n",
        "# Optional: if you want to align names with characters.json for consistency\n",
        "names_whitelist = set()\n",
        "if os.path.exists(\"characters.json\"):\n",
        "    try:\n",
        "        with open(\"characters.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "            for c in json.load(f):\n",
        "                if isinstance(c, dict) and \"char_name\" in c and c[\"char_name\"]:\n",
        "                    names_whitelist.add(c[\"char_name\"])\n",
        "    except Exception:\n",
        "        pass  # If parsing fails, we'll let the model infer names from the story\n",
        "\n",
        "schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"additionalProperties\": False,\n",
        "    \"properties\": {\n",
        "        \"scenes\": {\n",
        "            \"type\": \"array\",\n",
        "            \"minItems\": 10,\n",
        "            \"maxItems\": 10,\n",
        "            \"items\": {\n",
        "                \"type\": \"object\",\n",
        "                \"additionalProperties\": False,\n",
        "                \"properties\": {\n",
        "                    \"characters_involved\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\"type\": \"string\", \"minLength\": 1},\n",
        "                        \"minItems\": 1\n",
        "                    },\n",
        "                    \"scene_prompt\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"minLength\": 20,\n",
        "                        \"pattern\": r\"^Generate me image of\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"characters_involved\", \"scene_prompt\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"required\": [\"scenes\"]\n",
        "}\n",
        "\n",
        "# Build instruction\n",
        "whitelist_hint = \"\"\n",
        "if names_whitelist:\n",
        "    wl = \", \".join(sorted(names_whitelist))\n",
        "    whitelist_hint = f\"\"\"\n",
        "When listing characters_involved, prefer matching these known names exactly when applicable:\n",
        "[{wl}]\n",
        "\"\"\"\n",
        "\n",
        "instruction = f\"\"\"\n",
        "Read the fairy tale below and extract EXACTLY 10 key scenes in strict chronological order.\n",
        "For EACH scene return:\n",
        "- characters_involved: list of character names who appear materially in that moment\n",
        "- scene_prompt:  MUST start EXACTLY with \"Generate me image of\" and then describe a single vivid scene:\n",
        "  setting, time of day, mood, visible actions, and essential visual details. Avoid camera jargon.\n",
        "\n",
        "Constraints:\n",
        "- Keep prompts concise (1–2 sentences) but visually rich.\n",
        "- No spoilers or meta commentary.\n",
        "- Do NOT include dialogue lines.\n",
        "- Focus on distinct moments (no duplicates across scenes).\n",
        "\n",
        "{whitelist_hint}\n",
        "\n",
        "FAIRY TALE:\n",
        "{story}\n",
        "\"\"\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You output only JSON that matches the provided schema; be concise and precise.\"},\n",
        "        {\"role\": \"user\", \"content\": instruction}\n",
        "    ],\n",
        "    response_format={\n",
        "        \"type\": \"json_schema\",\n",
        "        \"json_schema\": {\n",
        "            \"name\": \"scene_list\",\n",
        "            \"strict\": True,\n",
        "            \"schema\": schema\n",
        "        }\n",
        "    },\n",
        "    temperature=0.5,\n",
        "    max_tokens=1600\n",
        ")\n",
        "\n",
        "raw = resp.choices[0].message.content\n",
        "data = json.loads(raw)\n",
        "scenes = data[\"scenes\"]\n",
        "\n",
        "# Pretty print\n",
        "print(\"✅ Extracted Scenes (10):\\n\")\n",
        "print(json.dumps(scenes, ensure_ascii=False, indent=2))\n",
        "\n",
        "# Save to file\n",
        "with open(\"scenes.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(scenes, f, ensure_ascii=False, indent=2)\n",
        "print(\"\\n💾 Saved to scenes.json\")\n"
      ],
      "metadata": {
        "id": "mSePTJeYme94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "i5OaGSpbopCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8a — Match Scenes to Character Images (Build refs list per scene)\n",
        "This cell loads scenes.json and characters_images/manifest.json, matches the characters_involved in each scene to their reference image paths, and outputs an array like:\n",
        "[{ \"chars_images\": [<paths>], \"scene_prompt\": \"<prompt>\" }, ... ].\n",
        "It also saves the result to scenes_with_refs.json for the next step."
      ],
      "metadata": {
        "id": "h2JlEbU3otoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔗 Match scenes to character reference images\n",
        "# Input:  scenes.json  +  characters_images/manifest.json\n",
        "# Output: scenes_with_refs.json -> [{ \"chars_images\": [...], \"scene_prompt\": \"...\" }, ...]\n",
        "\n",
        "import os, json\n",
        "\n",
        "SCENES_PATH = \"scenes.json\"\n",
        "MANIFEST_PATH = os.path.join(\"characters_images\", \"manifest.json\")\n",
        "OUT_PATH = \"scenes_with_refs.json\"\n",
        "\n",
        "# --- Load inputs ---\n",
        "assert os.path.exists(SCENES_PATH), \"scenes.json not found — run the scene extraction cell.\"\n",
        "assert os.path.exists(MANIFEST_PATH), \"characters_images/manifest.json not found — run the character image generation cell.\"\n",
        "\n",
        "with open(SCENES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    scenes = json.load(f)\n",
        "\n",
        "with open(MANIFEST_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    manifest = json.load(f)\n",
        "\n",
        "# --- Build name -> image path map (case-insensitive) ---\n",
        "name_to_path = {}\n",
        "for entry in manifest:\n",
        "    n = str(entry.get(\"char_name\", \"\")).strip()\n",
        "    p = entry.get(\"image_path\")\n",
        "    if n and p and os.path.exists(p):\n",
        "        name_to_path[n] = p\n",
        "\n",
        "def find_ref_paths(names):\n",
        "    \"\"\"Return unique image paths for provided character names, with best-effort matching.\"\"\"\n",
        "    paths = []\n",
        "    for raw in names or []:\n",
        "        query = str(raw).strip()\n",
        "        # exact\n",
        "        if query in name_to_path:\n",
        "            paths.append(name_to_path[query]); continue\n",
        "        # case-insensitive exact\n",
        "        lower_hit = next((name_to_path[k] for k in name_to_path if k.lower() == query.lower()), None)\n",
        "        if lower_hit:\n",
        "            paths.append(lower_hit); continue\n",
        "        # relaxed contains (Eliot the Brave -> Eliot)\n",
        "        contains_hit = next(\n",
        "            (name_to_path[k] for k in name_to_path\n",
        "             if query.lower() in k.lower() or k.lower() in query.lower()),\n",
        "            None\n",
        "        )\n",
        "        if contains_hit:\n",
        "            paths.append(contains_hit)\n",
        "        else:\n",
        "            print(f\"⚠️  No reference image found for character: '{raw}'\")\n",
        "    # dedupe preserve order\n",
        "    seen, uniq = set(), []\n",
        "    for p in paths:\n",
        "        if p not in seen:\n",
        "            uniq.append(p); seen.add(p)\n",
        "    return uniq\n",
        "\n",
        "# --- Build result structure for all scenes ---\n",
        "scenes_with_refs = []\n",
        "for sc in scenes:\n",
        "    chars = sc.get(\"characters_involved\", [])\n",
        "    prompt = sc.get(\"scene_prompt\", \"\")\n",
        "    refs = find_ref_paths(chars)\n",
        "    scenes_with_refs.append({\n",
        "        \"chars_images\": refs,\n",
        "        \"scene_prompt\": prompt\n",
        "    })\n",
        "\n",
        "# --- Save and preview ---\n",
        "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(scenes_with_refs, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✅ Built {len(scenes_with_refs)} scene entries with references.\")\n",
        "print(f\"💾 Saved to: {OUT_PATH}\\n\")\n",
        "print(json.dumps(scenes_with_refs[:3], ensure_ascii=False, indent=2))  # preview first 3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK6t_mHfpmWs",
        "outputId": "028f5d41-7731-47a1-8a5a-4fff1fe3e7b6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Built 10 scene entries with references.\n",
            "💾 Saved to: scenes_with_refs.json\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"chars_images\": [\n",
            "      \"characters_images/01_eliot.png\",\n",
            "      \"characters_images/02_rusty.png\"\n",
            "    ],\n",
            "    \"scene_prompt\": \"Generate me image of a sunny morning in the vibrant village of Starhaven, where Eliot, a curious boy with tousled hair and bright blue eyes, stands beside Rusty, a small humanoid robot made of scrap metal, as they prepare for an adventure amidst blooming flowers.\"\n",
            "  },\n",
            "  {\n",
            "    \"chars_images\": [\n",
            "      \"characters_images/01_eliot.png\",\n",
            "      \"characters_images/02_rusty.png\"\n",
            "    ],\n",
            "    \"scene_prompt\": \"Generate me image of Eliot and Rusty walking through the Enchanted Forest, surrounded by towering trees that whisper secrets, with Eliot's expression showing excitement mixed with doubt as the air thickens with magic.\"\n",
            "  },\n",
            "  {\n",
            "    \"chars_images\": [\n",
            "      \"characters_images/01_eliot.png\",\n",
            "      \"characters_images/02_rusty.png\",\n",
            "      \"characters_images/04_the_cloudsmith.png\"\n",
            "    ],\n",
            "    \"scene_prompt\": \"Generate me image of a clearing in the Enchanted Forest, where Eliot and Rusty approach the Cloudsmith, a wise figure in flowing robes, standing beside a magnificent swirling cloud that shimmers in the sunlight.\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8b — Generate Scene Images from scenes_with_refs.json (Gemini 2.5 Flash, with refs)\n",
        "This cell loads the prepared list of scenes (each with scene_prompt and chars_images), uploads the character images as reference inputs, and asks Gemini 2.5 Flash (preview) to compose the final scene image. Results are saved to scenes_images/ with a simple manifest."
      ],
      "metadata": {
        "id": "m9W1CBxNpl7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🎬 Generate scene images using prompts + character reference images (Gemini 2.5 Flash Preview)\n",
        "\n",
        "import os, json, base64, time, re\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import google.generativeai as genai\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-2.5-flash-image-preview\")\n",
        "\n",
        "# --- 2) Load scenes_with_refs.json ---\n",
        "IN_PATH = \"scenes_with_refs.json\"\n",
        "assert os.path.exists(IN_PATH), \"scenes_with_refs.json not found — run Cell 8a first.\"\n",
        "\n",
        "with open(IN_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    scenes_with_refs = json.load(f)\n",
        "\n",
        "assert isinstance(scenes_with_refs, list) and scenes_with_refs, \"Input must be a non-empty list.\"\n",
        "\n",
        "# --- 3) Output folder ---\n",
        "OUT_DIR = \"scenes_images\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# --- 4) Upload cache (avoid re-uploading same files repeatedly) ---\n",
        "_upload_cache = {}\n",
        "def upload_once(path: str):\n",
        "    if path in _upload_cache:\n",
        "        return _upload_cache[path]\n",
        "    f = genai.upload_file(path)\n",
        "    _upload_cache[path] = f\n",
        "    return f\n",
        "\n",
        "def safe_name(s: str) -> str:\n",
        "    s = re.sub(r\"\\s+\", \"_\", s.strip().lower())\n",
        "    return re.sub(r\"[^a-z0-9_\\-]\", \"\", s) or \"scene\"\n",
        "\n",
        "# --- 5) Core: generate a scene image with retries & inline image extraction ---\n",
        "def generate_scene_image(prompt: str, ref_paths, max_retries=3, base_delay=1.0):\n",
        "    parts = [prompt]\n",
        "    for p in (ref_paths or []):\n",
        "        if not os.path.exists(p):\n",
        "            print(f\"   ⚠️ ref not found, skipping: {p}\")\n",
        "            continue\n",
        "        try:\n",
        "            parts.append(upload_once(p))\n",
        "        except Exception as e:\n",
        "            print(f\"   ⚠️ upload failed for {p}: {e}\")\n",
        "\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            res = model.generate_content(\n",
        "                parts,\n",
        "                generation_config=genai.types.GenerationConfig(\n",
        "                    temperature=0.45,   # faithful to references\n",
        "                    candidate_count=1\n",
        "                ),\n",
        "            )\n",
        "            # Extract first inline image\n",
        "            content = res.candidates[0].content\n",
        "            for part in content.parts:\n",
        "                inline = getattr(part, \"inline_data\", None)\n",
        "                if inline and getattr(inline, \"mime_type\", \"\").startswith(\"image/\"):\n",
        "                    data = inline.data if isinstance(inline.data, (bytes, bytearray)) else base64.b64decode(inline.data)\n",
        "                    return Image.open(BytesIO(data))\n",
        "            raise RuntimeError(\"No image returned in response.\")\n",
        "        except Exception as e:\n",
        "            if attempt == max_retries:\n",
        "                raise\n",
        "            delay = base_delay * (2 ** (attempt - 1))\n",
        "            print(f\"   -> Attempt {attempt} failed: {e}. Retrying in {delay:.1f}s...\")\n",
        "            time.sleep(delay)\n",
        "\n",
        "# --- 6) Iterate and generate all scenes ---\n",
        "scene_manifest = []\n",
        "for i, entry in enumerate(scenes_with_refs, 1):\n",
        "    prompt = entry.get(\"scene_prompt\", \"\")\n",
        "    refs = entry.get(\"chars_images\", []) or []\n",
        "\n",
        "    if not prompt:\n",
        "        print(f\"[{i}/{len(scenes_with_refs)}] ❗ Missing scene_prompt — skipping.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"[{i}/{len(scenes_with_refs)}] Generating scene (refs: {len(refs)})\")\n",
        "    try:\n",
        "        img = generate_scene_image(prompt, refs)\n",
        "        fname = f\"{i:02d}_{safe_name(prompt[:50])}.png\"\n",
        "        out_path = os.path.join(OUT_DIR, fname)\n",
        "        img.save(out_path)\n",
        "        print(f\"   ✅ Saved: {out_path}\")\n",
        "        scene_manifest.append({\n",
        "            \"index\": i,\n",
        "            \"scene_prompt\": prompt,\n",
        "            \"image_path\": out_path,\n",
        "            \"reference_images\": [p for p in refs if os.path.exists(p)]\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Failed to generate scene {i}: {e}\")\n",
        "\n",
        "# --- 7) Save manifest ---\n",
        "MANIFEST_PATH = os.path.join(OUT_DIR, \"manifest.json\")\n",
        "with open(MANIFEST_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(scene_manifest, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\n📒 Scene manifest saved: {MANIFEST_PATH}\")\n",
        "print(f\"🗂️  Output folder: {os.path.abspath(OUT_DIR)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "ZfIbspscqJGm",
        "outputId": "153cf946-42b2-4e7c-d2c5-e0e15a29584a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/10] Generating scene (refs: 2)\n",
            "   ✅ Saved: scenes_images/01_generate_me_image_of_a_sunny_morning_in_the_vibran.png\n",
            "[2/10] Generating scene (refs: 2)\n",
            "   -> Attempt 1 failed: No image returned in response.. Retrying in 1.0s...\n",
            "   -> Attempt 2 failed: No image returned in response.. Retrying in 2.0s...\n",
            "   ❌ Failed to generate scene 2: No image returned in response.\n",
            "[3/10] Generating scene (refs: 3)\n",
            "   ✅ Saved: scenes_images/03_generate_me_image_of_a_clearing_in_the_enchanted_f.png\n",
            "[4/10] Generating scene (refs: 2)\n",
            "   ✅ Saved: scenes_images/04_generate_me_image_of_eliot_standing_before_the_clo.png\n",
            "[5/10] Generating scene (refs: 2)\n",
            "   ✅ Saved: scenes_images/05_generate_me_image_of_the_cloudsmith_waving_his_sta.png\n",
            "[6/10] Generating scene (refs: 2)\n",
            "   ✅ Saved: scenes_images/06_generate_me_image_of_eliot_closing_his_eyes_with_d.png\n",
            "[7/10] Generating scene (refs: 2)\n",
            "   -> Attempt 1 failed: No image returned in response.. Retrying in 1.0s...\n",
            "   -> Attempt 2 failed: No image returned in response.. Retrying in 2.0s...\n",
            "   ❌ Failed to generate scene 7: No image returned in response.\n",
            "[8/10] Generating scene (refs: 2)\n",
            "   ✅ Saved: scenes_images/08_generate_me_image_of_the_cloudsmith_smiling_approv.png\n",
            "[9/10] Generating scene (refs: 2)\n",
            "   ✅ Saved: scenes_images/09_generate_me_image_of_eliot_and_rusty_laughing_joyf.png\n",
            "[10/10] Generating scene (refs: 2)\n",
            "   ✅ Saved: scenes_images/10_generate_me_image_of_eliot_and_rusty_walking_back.png\n",
            "\n",
            "📒 Scene manifest saved: scenes_images/manifest.json\n",
            "🗂️  Output folder: /content/scenes_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔊 Text-to-Speech: Convert the fairy tale into an MP3 with ElevenLabs\n",
        "# - Loads `story` from memory or the newest saved story file.\n",
        "# - Splits long text into chunks safe for TTS.\n",
        "# - Synthesizes each chunk and merges into story_tts.mp3.\n",
        "# - Plays a short preview inline.\n",
        "\n",
        "import os, re, glob, io\n",
        "from datetime import datetime\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "# 1) Load story text (from variable or newest file)\n",
        "def load_story_text():\n",
        "    if \"story\" in globals() and isinstance(story, str) and story.strip():\n",
        "        return story.strip()\n",
        "    files = sorted(glob.glob(\"fairy_tale_story_*.txt\"))\n",
        "    if not files:\n",
        "        raise FileNotFoundError(\"No story text found. Generate the story first (Cell 5).\")\n",
        "    with open(files[-1], \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read().strip()\n",
        "\n",
        "text = load_story_text()\n",
        "\n",
        "# 2) Chunking (sentence-aware, ~1800 chars per chunk)\n",
        "def split_into_chunks(s, max_len=1800):\n",
        "    sentences = re.split(r'(?<=[\\.\\!\\?])\\s+', s)\n",
        "    chunks, buf = [], \"\"\n",
        "    for sent in sentences:\n",
        "        if len(buf) + len(sent) + 1 <= max_len:\n",
        "            buf = (buf + \" \" + sent).strip()\n",
        "        else:\n",
        "            if buf: chunks.append(buf)\n",
        "            buf = sent\n",
        "    if buf: chunks.append(buf)\n",
        "    return chunks\n",
        "\n",
        "chunks = split_into_chunks(text, max_len=1800)\n",
        "print(f\"🧩 Story length: {len(text):,} chars -> {len(chunks)} chunk(s)\")\n",
        "\n",
        "# 3) ElevenLabs client (API key from Colab userdata or env)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    ELEVEN_API_KEY = userdata.get(\"ELEVENLABS_API_KEY\") or os.getenv(\"ELEVENLABS_API_KEY\")\n",
        "except Exception:\n",
        "    ELEVEN_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")\n",
        "\n",
        "if not ELEVEN_API_KEY:\n",
        "    raise RuntimeError(\"Missing ELEVENLABS_API_KEY. Add it in Colab (userdata) or environment.\")\n",
        "\n",
        "from elevenlabs.client import ElevenLabs\n",
        "client = ElevenLabs(api_key=ELEVEN_API_KEY)\n",
        "\n",
        "# 4) Choose voice (use existing VOICE_ID if defined, else a stable default demo voice)\n",
        "VOICE_ID = globals().get(\"VOICE_ID\") or \"JBFqnCBsd6RMkjVDRZzb\"  # Rachel (demo) — change to your favorite\n",
        "VOICE_SETTINGS = {\n",
        "    \"stability\": 0.55,\n",
        "    \"similarity_boost\": 0.9,\n",
        "    \"style\": 0.35,\n",
        "    \"use_speaker_boost\": True\n",
        "}\n",
        "\n",
        "# 5) Generate audio for each chunk and merge using pydub\n",
        "!pip -q install pydub\n",
        "from pydub import AudioSegment\n",
        "\n",
        "out_dir = \"tts_output\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "chunk_paths = []\n",
        "\n",
        "for i, chunk in enumerate(chunks, 1):\n",
        "    print(f\"🎙️  Synthesizing chunk {i}/{len(chunks)}...\")\n",
        "    stream = client.text_to_speech.convert(\n",
        "        voice_id=VOICE_ID,\n",
        "        model_id=\"eleven_multilingual_v2\",\n",
        "        output_format=\"mp3_44100_128\",\n",
        "        text=chunk,\n",
        "        voice_settings=VOICE_SETTINGS\n",
        "    )\n",
        "    audio_bytes = b\"\".join(stream)\n",
        "    path = os.path.join(out_dir, f\"chunk_{i:02d}.mp3\")\n",
        "    with open(path, \"wb\") as f:\n",
        "        f.write(audio_bytes)\n",
        "    chunk_paths.append(path)\n",
        "\n",
        "# Merge all chunks\n",
        "final_name = f\"story_tts_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp3\"\n",
        "final_path = os.path.join(out_dir, final_name)\n",
        "\n",
        "merged = None\n",
        "for idx, p in enumerate(chunk_paths, 1):\n",
        "    seg = AudioSegment.from_file(p, format=\"mp3\")\n",
        "    merged = seg if merged is None else merged + seg\n",
        "\n",
        "if merged is None:\n",
        "    raise RuntimeError(\"No audio produced.\")\n",
        "merged.export(final_path, format=\"mp3\", bitrate=\"128k\")\n",
        "print(f\"✅ Final TTS saved: {final_path}\")\n",
        "\n",
        "# Inline preview (first ~20 seconds)\n",
        "preview = merged[:20_000]\n",
        "preview_path = os.path.join(out_dir, \"preview_20s.mp3\")\n",
        "preview.export(preview_path, format=\"mp3\", bitrate=\"128k\")\n",
        "display(Audio(preview_path))\n"
      ],
      "metadata": {
        "id": "nIN2tGMosqy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔊 Merge ElevenLabs TTS chunks into one narration MP3\n",
        "\n",
        "import glob, os\n",
        "from pydub import AudioSegment\n",
        "from datetime import datetime\n",
        "\n",
        "# Collect all chunk files\n",
        "chunks = sorted(glob.glob(\"tts_output/chunk_*.mp3\"))\n",
        "if not chunks:\n",
        "    raise FileNotFoundError(\"No TTS chunks found in tts_output/. Run the TTS cell first.\")\n",
        "\n",
        "print(f\"🧩 Found {len(chunks)} audio chunks\")\n",
        "\n",
        "# Merge them in order\n",
        "merged = None\n",
        "for c in chunks:\n",
        "    seg = AudioSegment.from_file(c, format=\"mp3\")\n",
        "    merged = seg if merged is None else merged + seg\n",
        "\n",
        "# Save final file\n",
        "final_name = f\"story_narration_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp3\"\n",
        "final_path = os.path.join(\"tts_output\", final_name)\n",
        "merged.export(final_path, format=\"mp3\", bitrate=\"128k\")\n",
        "\n",
        "print(f\"✅ Final narration saved: {final_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CA0M0MOudDb",
        "outputId": "d45c9239-921c-4914-ea7b-902ae4b22802"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧩 Found 2 audio chunks\n",
            "✅ Final narration saved: tts_output/story_narration_20250903_175723.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🎬 Simple and Reliable Slideshow Creator using FFmpeg\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import wave\n",
        "import contextlib\n",
        "import glob\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"🎬 Creating video slideshow using FFmpeg...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ---- A) Find or build narration audio ----\n",
        "def find_or_merge_audio():\n",
        "    # Look for existing audio files\n",
        "    candidates = (\n",
        "        sorted(glob.glob(\"tts_output/story_tts_*.mp3\")) +\n",
        "        sorted(glob.glob(\"tts_output/story_narration_*.mp3\")) +\n",
        "        sorted(glob.glob(\"story_tts_*.mp3\")) +\n",
        "        sorted(glob.glob(\"story_narration_*.mp3\"))\n",
        "    )\n",
        "    if candidates:\n",
        "        return candidates[-1]\n",
        "    if os.path.exists(\"story_narration.mp3\"):\n",
        "        return \"story_narration.mp3\"\n",
        "\n",
        "    # Try to merge chunks if available\n",
        "    chunks = sorted(glob.glob(\"tts_output/chunk_*.mp3\"))\n",
        "    if chunks:\n",
        "        print(f\"🔊 Found {len(chunks)} chunk(s). Merging...\")\n",
        "        try:\n",
        "            from pydub import AudioSegment\n",
        "        except ImportError:\n",
        "            subprocess.run([\"pip\", \"install\", \"pydub\"], check=True)\n",
        "            from pydub import AudioSegment\n",
        "\n",
        "        merged = None\n",
        "        for chunk in chunks:\n",
        "            segment = AudioSegment.from_file(chunk, format=\"mp3\")\n",
        "            merged = segment if merged is None else merged + segment\n",
        "\n",
        "        output_path = f\"story_narration_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp3\"\n",
        "        merged.export(output_path, format=\"mp3\", bitrate=\"128k\")\n",
        "        print(f\"✅ Merged audio: {output_path}\")\n",
        "        return output_path\n",
        "\n",
        "    raise FileNotFoundError(\"No narration audio found\")\n",
        "\n",
        "# ---- B) Find story images ----\n",
        "def find_story_images():\n",
        "    image_paths = []\n",
        "\n",
        "    # Try manifest first\n",
        "    manifest_path = os.path.join(\"scenes_images\", \"manifest.json\")\n",
        "    if os.path.exists(manifest_path):\n",
        "        with open(manifest_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            manifest = json.load(f)\n",
        "        for item in manifest:\n",
        "            path = item.get(\"image_path\")\n",
        "            if path and os.path.exists(path):\n",
        "                image_paths.append(path)\n",
        "\n",
        "    # Fallback to directory scan\n",
        "    if not image_paths:\n",
        "        for ext in [\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.bmp\", \"*.gif\"]:\n",
        "            image_paths.extend(sorted(glob.glob(os.path.join(\"scenes_images\", ext))))\n",
        "            if image_paths:\n",
        "                break\n",
        "\n",
        "    if not image_paths:\n",
        "        raise FileNotFoundError(\"No story images found in 'scenes_images/' directory\")\n",
        "\n",
        "    return image_paths\n",
        "\n",
        "# Get audio and images\n",
        "try:\n",
        "    audio_file = find_or_merge_audio()\n",
        "    print(f\"🎵 Using audio: {audio_file}\")\n",
        "\n",
        "    story_images = find_story_images()\n",
        "    print(f\"🖼️ Found {len(story_images)} story images\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"❌ {e}\")\n",
        "    exit(1)\n",
        "\n",
        "print(\"✅ Prerequisites check passed\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# ---- C) Install FFmpeg if needed ----\n",
        "try:\n",
        "    result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)\n",
        "    print(\"✅ FFmpeg is available\")\n",
        "except FileNotFoundError:\n",
        "    print(\"📦 Installing FFmpeg...\")\n",
        "    subprocess.run(['apt', 'update', '-qq'], check=True)\n",
        "    subprocess.run(['apt', 'install', '-y', 'ffmpeg'], check=True)\n",
        "    print(\"✅ FFmpeg installed\")\n",
        "\n",
        "print(\"-\" * 60)\n",
        "\n",
        "try:\n",
        "    # ---- D) Get audio duration ----\n",
        "    # Convert mp3 to wav to read duration (more reliable)\n",
        "    subprocess.run(['ffmpeg', '-i', audio_file, '-y', 'temp_audio.wav'],\n",
        "                   capture_output=True, check=True)\n",
        "\n",
        "    with contextlib.closing(wave.open('temp_audio.wav','r')) as f:\n",
        "        frames = f.getnframes()\n",
        "        rate = f.getframerate()\n",
        "        duration = frames / float(rate)\n",
        "\n",
        "    print(f\"🎵 Audio duration: {duration:.2f} seconds\")\n",
        "    print(f\"🖼️ Number of images: {len(story_images)}\")\n",
        "\n",
        "    # Calculate duration per image\n",
        "    duration_per_image = duration / len(story_images)\n",
        "    print(f\"⏱️ Duration per image: {duration_per_image:.2f} seconds\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # ---- E) Save images with numbered names for FFmpeg ----\n",
        "    from PIL import Image\n",
        "\n",
        "    image_files = []\n",
        "    for i, img_path in enumerate(story_images):\n",
        "        filename = f\"slide_{i:03d}.png\"\n",
        "\n",
        "        # Load and save image (ensure consistent format)\n",
        "        with Image.open(img_path) as img:\n",
        "            img = img.convert(\"RGB\")\n",
        "            img.save(filename, \"PNG\")\n",
        "\n",
        "        image_files.append(filename)\n",
        "        print(f\"💾 Saved: {filename}\")\n",
        "\n",
        "    print(\"-\" * 40)\n",
        "    print(\"🎞️ Creating video with FFmpeg...\")\n",
        "\n",
        "    # ---- F) Create video using FFmpeg ----\n",
        "    output_filename = f\"ai_story_slideshow_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4\"\n",
        "\n",
        "    ffmpeg_cmd = [\n",
        "        'ffmpeg',\n",
        "        '-y',  # Overwrite output file\n",
        "        '-framerate', f'1/{duration_per_image}',  # Frame rate (1 frame per duration)\n",
        "        '-i', 'slide_%03d.png',  # Input image pattern\n",
        "        '-i', audio_file,  # Input audio\n",
        "        '-c:v', 'libx264',  # Video codec\n",
        "        '-c:a', 'aac',  # Audio codec\n",
        "        '-pix_fmt', 'yuv420p',  # Pixel format for compatibility\n",
        "        '-shortest',  # Stop when shortest input ends\n",
        "        output_filename  # Output file\n",
        "    ]\n",
        "\n",
        "    print(f\"🔧 Running: ffmpeg with {len(image_files)} slides...\")\n",
        "    # Run FFmpeg command\n",
        "    result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)\n",
        "\n",
        "    if result.returncode == 0:\n",
        "        print(\"✅ Video created successfully!\")\n",
        "\n",
        "        # Get file info\n",
        "        file_size_mb = os.path.getsize(output_filename) / (1024*1024)\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"🎉 VIDEO SLIDESHOW COMPLETE!\")\n",
        "        print(f\"📁 Filename: {output_filename}\")\n",
        "        print(f\"📊 File size: {file_size_mb:.1f} MB\")\n",
        "        print(f\"⏱️ Duration: {duration:.1f} seconds\")\n",
        "        print(f\"🖼️ Images: {len(story_images)} scenes\")\n",
        "\n",
        "        # Clean up temporary files\n",
        "        for img_file in image_files:\n",
        "            try:\n",
        "                os.remove(img_file)\n",
        "            except:\n",
        "                pass\n",
        "        try:\n",
        "            os.remove('temp_audio.wav')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Check if we're in Jupyter for display\n",
        "        try:\n",
        "            from IPython.display import HTML, display\n",
        "            print(\"\\n🎬 Video Preview:\")\n",
        "            display(HTML(f'''\n",
        "            <video width=\"600\" controls style=\"max-width: 100%; border: 2px solid #ddd; border-radius: 8px;\">\n",
        "                <source src=\"{output_filename}\" type=\"video/mp4\">\n",
        "                <p>Your browser doesn't support video playback.</p>\n",
        "            </video>\n",
        "            '''))\n",
        "        except ImportError:\n",
        "            print(f\"\\n🎥 Video saved as: {output_filename}\")\n",
        "\n",
        "        print(\"\\n🎊 AI MULTIMEDIA STORYTELLING SUCCESS!\")\n",
        "        print(\"🚀 Your AI-generated slideshow is ready!\")\n",
        "\n",
        "    else:\n",
        "        print(\"❌ FFmpeg failed. Error output:\")\n",
        "        print(result.stderr)\n",
        "        print(\"\\nCommand used:\")\n",
        "        print(\" \".join(ffmpeg_cmd))\n",
        "        raise Exception(\"Video creation failed\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error creating video: {str(e)}\")\n",
        "    print(\"\\n💡 Check that:\")\n",
        "    print(\"  - Audio file exists and is valid MP3\")\n",
        "    print(\"  - Image files exist in scenes_images/ directory\")\n",
        "    print(\"  - FFmpeg is properly installed\")"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/ai_story_slideshow_20250903_182724.mp4": {
              "data": "",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "hCabMXevuODT",
        "outputId": "5338d62b-6241-4f00-821b-cf928fd09dcf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎬 Creating video slideshow using FFmpeg...\n",
            "============================================================\n",
            "🎵 Using audio: tts_output/story_narration_20250903_175723.mp3\n",
            "🖼️ Found 8 story images\n",
            "✅ Prerequisites check passed\n",
            "------------------------------------------------------------\n",
            "✅ FFmpeg is available\n",
            "------------------------------------------------------------\n",
            "🎵 Audio duration: 225.72 seconds\n",
            "🖼️ Number of images: 8\n",
            "⏱️ Duration per image: 28.22 seconds\n",
            "----------------------------------------\n",
            "💾 Saved: slide_000.png\n",
            "💾 Saved: slide_001.png\n",
            "💾 Saved: slide_002.png\n",
            "💾 Saved: slide_003.png\n",
            "💾 Saved: slide_004.png\n",
            "💾 Saved: slide_005.png\n",
            "💾 Saved: slide_006.png\n",
            "💾 Saved: slide_007.png\n",
            "----------------------------------------\n",
            "🎞️ Creating video with FFmpeg...\n",
            "🔧 Running: ffmpeg with 8 slides...\n",
            "✅ Video created successfully!\n",
            "============================================================\n",
            "🎉 VIDEO SLIDESHOW COMPLETE!\n",
            "📁 Filename: ai_story_slideshow_20250903_182724.mp4\n",
            "📊 File size: 3.6 MB\n",
            "⏱️ Duration: 225.7 seconds\n",
            "🖼️ Images: 8 scenes\n",
            "\n",
            "🎬 Video Preview:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <video width=\"600\" controls style=\"max-width: 100%; border: 2px solid #ddd; border-radius: 8px;\">\n",
              "                <source src=\"ai_story_slideshow_20250903_182724.mp4\" type=\"video/mp4\">\n",
              "                <p>Your browser doesn't support video playback.</p>\n",
              "            </video>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎊 AI MULTIMEDIA STORYTELLING SUCCESS!\n",
            "🚀 Your AI-generated slideshow is ready!\n"
          ]
        }
      ]
    }
  ]
}