{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Integrations for Developers ‚Äî Exam"
      ],
      "metadata": {
        "id": "8PySlKkufkth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions\n",
        "\n",
        "- This notebook is a **template** where you must put your code.  \n",
        "- You should **fill in all empty variables** and complete the code so that when I download your notebook and click **Run all**, all cells execute correctly and provide the answers.  \n",
        "- ‚ö†Ô∏è **Do NOT hardcode your API key**. Use Colab environment variables (`%env OPENAI_API_KEY=your_key_here`) and access them in your code.  \n",
        "- You may **create more cells** if needed. It is recommended that your code is well-structured and split logically into separate cells.  \n",
        "- The function **`ask_ai(query)`** must be implemented by you. All queries will call this function to check your solution.  \n",
        "- ‚úÖ **Test cases will be created by me (the instructor).** You are **not allowed to modify, remove, or add to the test cases cell**. Your code must work correctly with the provided test cases.  \n",
        "- You are **ONLY ALLOWED** to use only the following:  \n",
        "  - **Models:** OpenAI or Anthropic  \n",
        "  - **Technologies:** LangChain or vanilla Python code  \n",
        "  - **Vector Store:** Chroma DB\n",
        "\n",
        "üö® **Any student who does not follow the template, does not stick to the required format, or whose code does not execute properly will be disqualified.**\n"
      ],
      "metadata": {
        "id": "SL2vj_IDfuxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important\n",
        "\n",
        "Fill in **all the variables** in the cell.  \n",
        "‚ùå **Do NOT put your API key directly in the code.**  \n",
        "‚úÖ The cell must be set up to take the API key from the Colab environment variables.\n"
      ],
      "metadata": {
        "id": "a6q8k6WrgeNc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6USRQ_svffQK"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# üîß RAG Configuration Variables\n",
        "# ================================\n",
        "\n",
        "# ‚ö†Ô∏è Do NOT put your API key here directly.\n",
        "# Make sure you set your API key in Colab like this:\n",
        "# %env OPENAI_API_KEY=your_key_here\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# API Key (taken from Colab environment variables)\n",
        "API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Prompt & Model Settings\n",
        "PROMPT = \"\"            # e.g. \"Summarize the document in 3 sentences\"\n",
        "MODEL = \"\"             # e.g. \"gpt-4\"\n",
        "EMBEDDING_MODEL = \"\"   # e.g. \"text-embedding-ada-002\"\n",
        "\n",
        "# Chunking Parameters\n",
        "CHUNK_SIZE =             # e.g. 500\n",
        "CHUNK_OVERLAP =          # e.g. 50\n",
        "TOP_N_RESULTS =          # e.g. 3\n",
        "\n",
        "# Generation Parameters\n",
        "OUTPUT_LENGTH =           # e.g. 200\n",
        "TEMPERATURE =             # e.g. 0.7"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Organization\n",
        "\n",
        "Create more cells if needed and put your code in them.  \n",
        "It is **recommended** that your code is well-structured, split logically, and kept in separate cells for clarity.\n"
      ],
      "metadata": {
        "id": "b0u-pPNriGQk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W0aZh8315g55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sr7fql2C5g2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gEzWeB945g0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0TX77N_c5gxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t8O03AMV5guB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hNDt5cn95gqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ianJyYu95gkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-DmK6emx5gcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Cases (Final Cell)\n",
        "\n",
        "The final cell must contain your **test cases**.  \n",
        "When executed, the AI should provide correct answers to the given questions **based on the PDF file**.\n"
      ],
      "metadata": {
        "id": "b2S9Kbftik_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AI Query Function\n",
        "\n",
        "In this cell, you must implement the function **ask_ai(query)**.  \n",
        "This function will be the final execution point of your pipeline (RAG / LLM).  \n"
      ],
      "metadata": {
        "id": "r7v46jYqjg3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# ‚ùì AI Query Function\n",
        "# ================================\n",
        "\n",
        "def ask_ai(query: str):\n",
        "    \"\"\"\n",
        "    This function should execute your final RAG / LLM pipeline.\n",
        "    Input:\n",
        "        query (str): The question you want to ask the AI.\n",
        "    Output:\n",
        "        str: The AI's answer based on the PDF file.\n",
        "    \"\"\"\n",
        "    # TODO: Implement your final execution logic here\n",
        "    # Example steps:\n",
        "    # 1. Retrieve relevant chunks\n",
        "    # 2. Generate embeddings\n",
        "    # 3. Call the model with your prompt + retrieved context\n",
        "    # 4. Return the model's answer\n",
        "\n",
        "    raise NotImplementedError(\"You must implement this function\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhBbP3s8imoU",
        "outputId": "19f18cee-de5c-42eb-bfd2-b190dd5bdf9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ask_ai(query) is ready. Try: ask_ai('Your question here')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Queries\n",
        "\n",
        "Use this cell to test your function with different queries.  \n",
        "The answers must be generated correctly based on the PDF file.  \n"
      ],
      "metadata": {
        "id": "3s4yDNiGjmV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# üîç Example Queries for Testing\n",
        "# ================================\n",
        "\n",
        "queries = [\n",
        "    \"How many words should effective prompts average?\",\n",
        "    \"List the four main areas for effective prompts.\",\n",
        "    \"What does 'persona' mean in prompt writing?\",\n",
        "    \"Name three business roles covered in this guide.\",\n",
        "    \"What is Gemini Advanced?\"\n",
        "]\n",
        "\n",
        "# Call the AI with each query\n",
        "for q in queries:\n",
        "    print(f\"Q: {q}\")\n",
        "    print(f\"A: {ask_ai(q)}\\n\")\n"
      ],
      "metadata": {
        "id": "dw5VE1YSjmHk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}